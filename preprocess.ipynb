{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f438c938",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Admin\\Documents\\ma\n",
      "[nltk_data]     rianneSimplon\\simplon\\sentiment_analysis_virtual\\env\\l\n",
      "[nltk_data]     ib\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Admin\\Documents\\ma\n",
      "[nltk_data]     rianneSimplon\\simplon\\sentiment_analysis_virtual\\env\\l\n",
      "[nltk_data]     ib\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to C:\\Users\n",
      "[nltk_data]     \\Admin\\Documents\\marianneSimplon\\simplon\\sentiment_ana\n",
      "[nltk_data]     lysis_virtual\\env\\lib\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Connexion\n",
    "import mysql.connector\n",
    "import sys\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import string\n",
    "from nltk import *\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger') #pour pos_tag\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix, classification_report, accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32ff0e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect():\n",
    "    try:\n",
    "        cnx = mysql.connector.connect(host=\"localhost\",user=\"root\",password=\"root\",auth_plugin='mysql_native_password',database=\"sentiment_analysis\")\n",
    "    except mysql.connector.Error as err:\n",
    "        cnx = False\n",
    "        print(err)\n",
    "        sys.exit(1)\n",
    "    finally:\n",
    "        return cnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "686cf01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = connect()\n",
    "conn\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "254354e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe():\n",
    "    cursor.execute(\"\"\"  SELECT *\n",
    "                    FROM clothing_reviews; \"\"\")\n",
    "    rows = cursor.fetchall()\n",
    "    df = pd.DataFrame(rows,columns=['Index','Clothing ID', 'Age', 'Title', 'Review Text', 'Rating',\n",
    "       'Recommended IND', 'Positive Feedback Count', 'Division Name',\n",
    "       'Department Name', 'Class Name'])\n",
    "    df = df.set_index('Index')\n",
    "    df = df.replace('',np.nan,regex = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72aeefda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ori = create_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b020fe",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14df7853",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppression de 845 donn√©es car il nous faut absolument TOUTES les Review Text\n",
    "df_ori.dropna(subset=['Review Text'], inplace=True)\n",
    "# df_ori.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d890f1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_ori[[\"Review Text\",\"Recommended IND\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6239b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82dc386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    else:\n",
    "        return wn.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f405f037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(data):\n",
    "    \n",
    "    #1. Tokenize\n",
    "    text_tokens = word_tokenize(data.replace(\"'\", \"\").lower()) \n",
    "        \n",
    "    #2. Remove Puncs\n",
    "    tokens_without_punc = [w for w in text_tokens if w.isalpha()]  \n",
    "    \n",
    "    #3. Removing Stopwords\n",
    "    tokens_without_sw = [t for t in tokens_without_punc if t not in stop_words]\n",
    "    \n",
    "    #4. Lemmatize\n",
    "    POS_tagging = pos_tag(tokens_without_sw)\n",
    "    wordnet_pos_tag=[]\n",
    "    wordnet_pos_tag = [(word, get_wordnet_pos(pos_tag)) for (word, pos_tag) in POS_tagging]\n",
    "    wnl = WordNetLemmatizer()\n",
    "    lemma = [wnl.lemmatize(word, tag) for word, tag in wordnet_pos_tag]\n",
    "    \n",
    "    return \" \".join(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94acb500",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_209716\\4105619847.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Document'] = df['Review Text'].apply(cleaning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Document</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>1</td>\n",
       "      <td>absolutely wonderful silky sexy comfortable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>1</td>\n",
       "      <td>love dress sooo pretty happen find store im gl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>0</td>\n",
       "      <td>high hope dress really wanted work initially o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>1</td>\n",
       "      <td>love love love jumpsuit fun flirty fabulous ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>1</td>\n",
       "      <td>shirt flatter due adjustable front tie perfect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23482</th>\n",
       "      <td>I was very happy to snag this dress at such a ...</td>\n",
       "      <td>1</td>\n",
       "      <td>happy snag dress great price easy slip flatter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23483</th>\n",
       "      <td>It reminds me of maternity clothes. soft, stre...</td>\n",
       "      <td>1</td>\n",
       "      <td>reminds maternity clothes soft stretchy shiny ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23484</th>\n",
       "      <td>This fit well, but the top was very see throug...</td>\n",
       "      <td>0</td>\n",
       "      <td>fit well top see never would work im glad able...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23485</th>\n",
       "      <td>I bought this dress for a wedding i have this ...</td>\n",
       "      <td>1</td>\n",
       "      <td>buy dress wed summer cute unfortunately fit is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23486</th>\n",
       "      <td>This dress in a lovely platinum is feminine an...</td>\n",
       "      <td>1</td>\n",
       "      <td>dress lovely platinum feminine fit perfectly e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22641 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Review Text  Recommended IND  \\\n",
       "Index                                                                       \n",
       "1      Absolutely wonderful - silky and sexy and comf...                1   \n",
       "2      Love this dress!  it's sooo pretty.  i happene...                1   \n",
       "3      I had such high hopes for this dress and reall...                0   \n",
       "4      I love, love, love this jumpsuit. it's fun, fl...                1   \n",
       "5      This shirt is very flattering to all due to th...                1   \n",
       "...                                                  ...              ...   \n",
       "23482  I was very happy to snag this dress at such a ...                1   \n",
       "23483  It reminds me of maternity clothes. soft, stre...                1   \n",
       "23484  This fit well, but the top was very see throug...                0   \n",
       "23485  I bought this dress for a wedding i have this ...                1   \n",
       "23486  This dress in a lovely platinum is feminine an...                1   \n",
       "\n",
       "                                                Document  \n",
       "Index                                                     \n",
       "1            absolutely wonderful silky sexy comfortable  \n",
       "2      love dress sooo pretty happen find store im gl...  \n",
       "3      high hope dress really wanted work initially o...  \n",
       "4      love love love jumpsuit fun flirty fabulous ev...  \n",
       "5      shirt flatter due adjustable front tie perfect...  \n",
       "...                                                  ...  \n",
       "23482  happy snag dress great price easy slip flatter...  \n",
       "23483  reminds maternity clothes soft stretchy shiny ...  \n",
       "23484  fit well top see never would work im glad able...  \n",
       "23485  buy dress wed summer cute unfortunately fit is...  \n",
       "23486  dress lovely platinum feminine fit perfectly e...  \n",
       "\n",
       "[22641 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Document'] = df['Review Text'].apply(cleaning)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f258634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('./datasets/df_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a81bc36",
   "metadata": {},
   "source": [
    "# Data Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a998e7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"Document\"].values\n",
    "y = df[\"Recommended IND\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7122f589",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state = 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ae4aa8",
   "metadata": {},
   "source": [
    "##### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea6b9012",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8eaae673",
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=42,sampling_strategy=0.6)\n",
    "X_rus, y_rus = rus.fit_resample(X_train.reshape(-1, 1), y_train.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "52d29afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape en tableau pour passer dans le tokenizer\n",
    "X_train_rus = X_rus.reshape(-1)\n",
    "y_train_rus = y_rus.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d104074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_rus_autoML et y_rus_autoML pour tester autoML\n",
    "X_rus_autoML = np.concatenate((X_train_rus, X_test))\n",
    "y_rus_autoML = np.concatenate((y_train_rus, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4143ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    14831\n",
      "0     3281\n",
      "dtype: int64\n",
      "1    5468\n",
      "0    3281\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(y_train).value_counts())\n",
    "print(pd.DataFrame(y_rus).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b0f8d183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(x=y_train)\n",
    "plt.title('Reparition before RandomUnderSampler')\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.countplot(x=y_rus)\n",
    "plt.title('Reparition after RandomUnderSampler')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0f27815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Re-tokeniser\n",
    "# X_train_rus_tok = word_tokenize(pd.Series(X_train_rus).replace(\"'\", \"\"))\n",
    "# X_train_rus_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5dedaa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "\n",
    "# vectorizer = CountVectorizer()\n",
    "vectorizer = TfidfVectorizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2674f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trans = vectorizer.fit_transform(X_train_rus)\n",
    "X_test_trans = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0083814b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8749x7512 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 223581 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "550c849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_preprocess(file_name):\n",
    "    with open(f\"./pickle_preprocess/{file_name}.pickle\", 'wb') as handle:\n",
    "        pickle.dump(vectorizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53537a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_preprocess(\"CountVectorizer\")\n",
    "# save_preprocess(\"TfidfVectorizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c983f7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(model, X_train, X_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    \n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"Train_Set\")\n",
    "    print(classification_report(y_train,y_pred_train))\n",
    "    print(\"Test_Set\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    plot_confusion_matrix(model, X_test, y_test, cmap=\"plasma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27502148",
   "metadata": {},
   "source": [
    "R√©√©quilibrage des donn√©es\n",
    "\n",
    "Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcf1452",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "eb4dc6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./pickle_preprocess/TfidfVectorizer.pickle','rb') as fe_data_file:\n",
    "     data = pickle.load(fe_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29c94bf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28b1db44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# vectorizer.inverse_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542ad682",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C = 0.1, max_iter = 1000, class_weight = 'balanced', random_state = 101)\n",
    "logreg.fit(X_train_count,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2461210",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LogReg_Count Model\")\n",
    "print (\"------------------\")\n",
    "eval(logreg_count, X_train_count, X_test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a8a5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('model.pickle', 'wb') as handle:\n",
    "#    pickle.dump(model, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acee3cd",
   "metadata": {},
   "source": [
    "##### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1276ff93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lazypredict.Supervised import LazyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8448d308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c10eb83e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [56:38<00:00, 117.18s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.90</td>\n",
       "      <td>5.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>14.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.92</td>\n",
       "      <td>6.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.92</td>\n",
       "      <td>133.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "      <td>107.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "      <td>42.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVC</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>770.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.90</td>\n",
       "      <td>128.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.86</td>\n",
       "      <td>94.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.92</td>\n",
       "      <td>626.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>12.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.84</td>\n",
       "      <td>14.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.85</td>\n",
       "      <td>9.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.82</td>\n",
       "      <td>77.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.90</td>\n",
       "      <td>336.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.83</td>\n",
       "      <td>307.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.83</td>\n",
       "      <td>20.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.83</td>\n",
       "      <td>326.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.83</td>\n",
       "      <td>27.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.91</td>\n",
       "      <td>14.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.81</td>\n",
       "      <td>6.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.42</td>\n",
       "      <td>7.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.73</td>\n",
       "      <td>205.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.90</td>\n",
       "      <td>16.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelSpreading</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelPropagation</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.90</td>\n",
       "      <td>5.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                           \n",
       "NearestCentroid                    0.85               0.84     0.84      0.86   \n",
       "LGBMClassifier                     0.87               0.83     0.83      0.88   \n",
       "BernoulliNB                        0.87               0.83     0.83      0.87   \n",
       "XGBClassifier                      0.87               0.81     0.81      0.87   \n",
       "ExtraTreesClassifier               0.88               0.81     0.81      0.88   \n",
       "RandomForestClassifier             0.88               0.80     0.80      0.88   \n",
       "NuSVC                              0.86               0.77     0.77      0.86   \n",
       "AdaBoostClassifier                 0.83               0.77     0.77      0.84   \n",
       "BaggingClassifier                  0.79               0.76     0.76      0.81   \n",
       "SVC                                0.86               0.75     0.75      0.86   \n",
       "LogisticRegression                 0.78               0.74     0.74      0.80   \n",
       "PassiveAggressiveClassifier        0.75               0.73     0.73      0.78   \n",
       "Perceptron                         0.77               0.72     0.72      0.79   \n",
       "LinearSVC                          0.73               0.72     0.72      0.76   \n",
       "CalibratedClassifierCV             0.84               0.72     0.72      0.84   \n",
       "RidgeClassifierCV                  0.75               0.71     0.71      0.77   \n",
       "RidgeClassifier                    0.74               0.71     0.71      0.77   \n",
       "LinearDiscriminantAnalysis         0.74               0.71     0.71      0.77   \n",
       "DecisionTreeClassifier             0.74               0.70     0.70      0.77   \n",
       "SGDClassifier                      0.85               0.69     0.69      0.84   \n",
       "ExtraTreeClassifier                0.71               0.65     0.65      0.74   \n",
       "GaussianNB                         0.38               0.55     0.55      0.40   \n",
       "QuadraticDiscriminantAnalysis      0.60               0.55     0.55      0.65   \n",
       "KNeighborsClassifier               0.82               0.54     0.54      0.76   \n",
       "LabelSpreading                     0.18               0.50     0.50      0.06   \n",
       "LabelPropagation                   0.18               0.50     0.50      0.06   \n",
       "DummyClassifier                    0.82               0.50     0.50      0.74   \n",
       "\n",
       "                               f1_score  Time Taken  \n",
       "Model                                                \n",
       "NearestCentroid                    0.90        5.85  \n",
       "LGBMClassifier                     0.92       14.83  \n",
       "BernoulliNB                        0.92        6.89  \n",
       "XGBClassifier                      0.92      133.23  \n",
       "ExtraTreesClassifier               0.93      107.61  \n",
       "RandomForestClassifier             0.93       42.46  \n",
       "NuSVC                              0.91      770.62  \n",
       "AdaBoostClassifier                 0.90      128.32  \n",
       "BaggingClassifier                  0.86       94.45  \n",
       "SVC                                0.92      626.17  \n",
       "LogisticRegression                 0.86       12.59  \n",
       "PassiveAggressiveClassifier        0.84       14.04  \n",
       "Perceptron                         0.85        9.13  \n",
       "LinearSVC                          0.82       77.49  \n",
       "CalibratedClassifierCV             0.90      336.86  \n",
       "RidgeClassifierCV                  0.83      307.75  \n",
       "RidgeClassifier                    0.83       20.79  \n",
       "LinearDiscriminantAnalysis         0.83      326.87  \n",
       "DecisionTreeClassifier             0.83       27.45  \n",
       "SGDClassifier                      0.91       14.76  \n",
       "ExtraTreeClassifier                0.81        6.40  \n",
       "GaussianNB                         0.42        7.26  \n",
       "QuadraticDiscriminantAnalysis      0.73      205.15  \n",
       "KNeighborsClassifier               0.90       16.74  \n",
       "LabelSpreading                     0.00       34.95  \n",
       "LabelPropagation                   0.00       34.43  \n",
       "DummyClassifier                    0.90        5.09  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LazyClassifier(predictions=True,verbose=0,ignore_warnings=True,custom_metric=f1_score)\n",
    "# clf = LazyClassifier(verbose=0,ignore_warnings=True)\n",
    "models,predictions = clf.fit(pd.DataFrame(X_train_trans.toarray()), pd.DataFrame(X_test_trans.toarray()), y_train_rus, y_test)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5bc112df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazytextpredict import basic_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ea85ba8b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting pandas series to list\n",
      "converting pandas series to list\n",
      "X_train length: 11950\n",
      "X_test length: 1328\n",
      "Y_train length: 11950\n",
      "Y_test length: 1328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on a dataset with 2 labels\n",
      "ERROR\n",
      "best parameters are:\n",
      "{'clf__alpha': 0.001, 'clf__penalty': 'l2', 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}\n",
      "{'eval_loss': 0.27936746987951805, 'eval_accuracy': 0.7206325301204819, 'eval_f1': 0.5080278195225946, 'eval_precision': 0.8232527929332294, 'eval_recall': 0.5495855252670174, 'eval_full_report': '              precision    recall  f1-score   support\\n\\n           0       0.93      0.10      0.18       410\\n           1       0.71      1.00      0.83       918\\n\\n    accuracy                           0.72      1328\\n   macro avg       0.82      0.55      0.51      1328\\nweighted avg       0.78      0.72      0.63      1328\\n'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on a dataset with 2 labels\n",
      "ERROR\n",
      "best parameters are:\n",
      "{'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)}\n",
      "{'eval_loss': 0.16114457831325302, 'eval_accuracy': 0.838855421686747, 'eval_f1': 0.8187805282422109, 'eval_precision': 0.8095139464236398, 'eval_recall': 0.8335033742494287, 'eval_full_report': '              precision    recall  f1-score   support\\n\\n           0       0.71      0.82      0.76       410\\n           1       0.91      0.85      0.88       918\\n\\n    accuracy                           0.84      1328\\n   macro avg       0.81      0.83      0.82      1328\\nweighted avg       0.85      0.84      0.84      1328\\n'}\n",
      "CPU times: total: 8.67 s\n",
      "Wall time: 41.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trial=basic_classification.LTP(Xdata=pd.Series(X_rus_autoML),Ydata=pd.Series(y_rus_autoML), models='count-vectorizer')\n",
    "trial.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d1dbdc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Model            loss        accuracy              f1       precision          recall\n",
      "               linear_SVM         0.27937         0.72063         0.50803         0.82325         0.54959\n",
      "multinomial_naive_bayesian         0.16114         0.83886         0.81878         0.80951          0.8335\n"
     ]
    }
   ],
   "source": [
    "trial.print_metrics_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "23187d55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting pandas series to list\n",
      "converting pandas series to list\n",
      "X_train length: 11950\n",
      "X_test length: 1328\n",
      "Y_train length: 11950\n",
      "Y_test length: 1328\n",
      "Training on a dataset with 2 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\Admin/.cache\\huggingface\\hub\\models--bert-base-uncased\\snapshots\\0a6aa9128b6194f4f3c4db429b6cb4891cdb421b\\config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Admin/.cache\\huggingface\\hub\\models--bert-base-uncased\\snapshots\\0a6aa9128b6194f4f3c4db429b6cb4891cdb421b\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading file vocab.txt from cache at C:\\Users\\Admin/.cache\\huggingface\\hub\\models--bert-base-uncased\\snapshots\\0a6aa9128b6194f4f3c4db429b6cb4891cdb421b\\vocab.txt\n",
      "loading file tokenizer.json from cache at C:\\Users\\Admin/.cache\\huggingface\\hub\\models--bert-base-uncased\\snapshots\\0a6aa9128b6194f4f3c4db429b6cb4891cdb421b\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\Admin/.cache\\huggingface\\hub\\models--bert-base-uncased\\snapshots\\0a6aa9128b6194f4f3c4db429b6cb4891cdb421b\\tokenizer_config.json\n",
      "loading configuration file config.json from cache at C:\\Users\\Admin/.cache\\huggingface\\hub\\models--bert-base-uncased\\snapshots\\0a6aa9128b6194f4f3c4db429b6cb4891cdb421b\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "577d2fdeac3e4ea2862a2ab0adc788f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d227cd370ec84beb921455ef0fec0a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 11950\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3735\n",
      "  Number of trainable parameters = 109483778\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='340' max='3735' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 340/3735 18:23:43 < 184:46:12, 0.01 it/s, Epoch 0.45/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:2\u001b[0m\n",
      "File \u001b[1;32m~\\Documents\\marianneSimplon\\simplon\\sentiment_analysis_virtual\\env\\lib\\site-packages\\lazytextpredict\\basic_classification.py:267\u001b[0m, in \u001b[0;36mLTP.run\u001b[1;34m(self, focused, focused_model, training_epochs)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    261\u001b[0m \ttrainer \u001b[38;5;241m=\u001b[39m Trainer(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    262\u001b[0m \t                      args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m    263\u001b[0m \t                      compute_metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics,\n\u001b[0;32m    264\u001b[0m \t                      train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[0;32m    265\u001b[0m \t                      eval_dataset\u001b[38;5;241m=\u001b[39mtest_dataset\n\u001b[0;32m    266\u001b[0m \t)\n\u001b[1;32m--> 267\u001b[0m \t\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m \tcurr_metrics \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[0;32m    269\u001b[0m \ttrainer\u001b[38;5;241m.\u001b[39msave_model(model_name\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\marianneSimplon\\simplon\\sentiment_analysis_virtual\\env\\lib\\site-packages\\transformers\\trainer.py:1501\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m   1498\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1499\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1500\u001b[0m )\n\u001b[1;32m-> 1501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\marianneSimplon\\simplon\\sentiment_analysis_virtual\\env\\lib\\site-packages\\transformers\\trainer.py:1749\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1747\u001b[0m         tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   1748\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1749\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1752\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1754\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1755\u001b[0m ):\n\u001b[0;32m   1756\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32m~\\Documents\\marianneSimplon\\simplon\\sentiment_analysis_virtual\\env\\lib\\site-packages\\transformers\\trainer.py:2508\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   2507\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 2508\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   2511\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\marianneSimplon\\simplon\\sentiment_analysis_virtual\\env\\lib\\site-packages\\transformers\\trainer.py:2540\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   2538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2539\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2540\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2541\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   2542\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   2543\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\Documents\\marianneSimplon\\simplon\\sentiment_analysis_virtual\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Documents\\marianneSimplon\\simplon\\sentiment_analysis_virtual\\env\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1552\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1544\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1545\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1547\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1550\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1552\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1553\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1560\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1562\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1566\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[1;32m~\\Documents\\marianneSimplon\\simplon\\sentiment_analysis_virtual\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Documents\\marianneSimplon\\simplon\\sentiment_analysis_virtual\\env\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1014\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1005\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1007\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m   1008\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1009\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1027\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\marianneSimplon\\simplon\\sentiment_analysis_virtual\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Documents\\marianneSimplon\\simplon\\sentiment_analysis_virtual\\env\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:603\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    594\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[0;32m    595\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    596\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    600\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    601\u001b[0m     )\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 603\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    614\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\Documents\\marianneSimplon\\simplon\\sentiment_analysis_virtual\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Documents\\marianneSimplon\\simplon\\sentiment_analysis_virtual\\env\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:489\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    479\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    487\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    488\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    496\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    498\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\marianneSimplon\\simplon\\sentiment_analysis_virtual\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Documents\\marianneSimplon\\simplon\\sentiment_analysis_virtual\\env\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:419\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    411\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    417\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    418\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 419\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    428\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    429\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\marianneSimplon\\simplon\\sentiment_analysis_virtual\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Documents\\marianneSimplon\\simplon\\sentiment_analysis_virtual\\env\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:308\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    307\u001b[0m     key_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey(hidden_states))\n\u001b[1;32m--> 308\u001b[0m     value_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    310\u001b[0m query_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(mixed_query_layer)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder:\n\u001b[0;32m    313\u001b[0m     \u001b[38;5;66;03m# if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;66;03m# Further calls to cross_attention layer can then reuse all cross-attention\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;66;03m# can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;66;03m# if encoder bi-directional self-attention `past_key_value` is always `None`\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\marianneSimplon\\simplon\\sentiment_analysis_virtual\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Documents\\marianneSimplon\\simplon\\sentiment_analysis_virtual\\env\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trial=basic_classification.LTP(Xdata=pd.Series(X_rus_autoML),Ydata=pd.Series(y_rus_autoML), models='transformers')\n",
    "trial.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "be2ddc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Model            loss        accuracy              f1       precision          recall\n"
     ]
    }
   ],
   "source": [
    "trial.print_metrics_table()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
